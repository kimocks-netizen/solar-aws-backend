all some of these columns are wrong the goal remember is to public a topic to aws then plc will use that information to do the calculation so lets only create a table for weather columns only 
ChatGPT said:
Thought for 8s

Got it ‚Äî we‚Äôll trim the schema down to weather-only and design a clean table you can use with DynamoDB (recommended for weather telemetry/forecasts because of scale and low operational overhead). I‚Äôll give you:

a suggested table name + primary key design,

recommended attributes (columns) for weather/forecast data only,

an AWS CLI create-table command for DynamoDB,

a sample item (JSON) showing how a stored record looks,

extra recommendations (TTL, GSIs, retention, IoT Rule note).

1 ‚Äî Design decision (keys)

For weather data you generally want to query by location and time.
Recommended primary key:

Partition key (PK): location (string) ‚Äî use consistent location IDs (lat_lon or site name or geohash).

Sort key (SK): timestamp (string in ISO 8601, e.g. 2025-10-19T09:00:00Z) ‚Äî allows efficient range queries (last 24h, last 7 days, etc.)

This lets you do: Query(Table, KeyCondition: location = "site-001" AND timestamp BETWEEN a AND b) cheaply.

2 ‚Äî Recommended attributes (weather-only)

Keep it focused ‚Äî you can attach PLC telemetry elsewhere (in a different table or reference).

location (PK) ‚Äî e.g. "-25.746,28.188" or "site-manchester-01"

timestamp (SK) ‚Äî ISO8601 UTC

forecast_horizon ‚Äî integer (hours ahead; 0 = now, 1 = +1h etc.)

temperature_c ‚Äî number

irradiance_w_m2 ‚Äî number (GHI or the specific irradiance metric from Tomorrow.io)

cloud_cover_pct ‚Äî number (0‚Äì100)

weather_code ‚Äî number or string (provider code describing conditions)

wind_speed_m_s ‚Äî number

humidity_pct ‚Äî number

precipitation_mm ‚Äî number (if present)

source ‚Äî string ("tomorrow.io")

created_at ‚Äî ISO8601 when you saved record

ttl_epoch ‚Äî optional number (Unix epoch seconds) if you want automatic expiry (DynamoDB TTL)

You can also add meta (map) for provider-specific extras.

3 ‚Äî AWS CLI command to create table (DynamoDB)

Run this locally (AWS CLI configured for your account & region):

aws dynamodb create-table \
  --table-name weather_data \
  --attribute-definitions \
    AttributeName=location,AttributeType=S \
    AttributeName=timestamp,AttributeType=S \
  --key-schema \
    AttributeName=location,KeyType=HASH \
    AttributeName=timestamp,KeyType=RANGE \
  --provisioned-throughput ReadCapacityUnits=5,WriteCapacityUnits=5 \
  --region eu-north-1


Notes:

You can use --billing-mode PAY_PER_REQUEST instead of provisioned throughput:

--billing-mode PAY_PER_REQUEST


That‚Äôs simpler and often ideal for variable IoT loads.

4 ‚Äî Example item (DynamoDB JSON format)

A sample PutItem payload (readable JSON) showing the fields:

{
  "TableName": "weather_data",
  "Item": {
    "location": { "S": "-25.746,28.188" },
    "timestamp": { "S": "2025-10-19T09:00:00Z" },
    "forecast_horizon": { "N": "0" },
    "temperature_c": { "N": "23.4" },
    "irradiance_w_m2": { "N": "820" },
    "cloud_cover_pct": { "N": "12" },
    "weather_code": { "S": "clear" },
    "wind_speed_m_s": { "N": "4.3" },
    "humidity_pct": { "N": "60" },
    "precipitation_mm": { "N": "0.0" },
    "source": { "S": "tomorrow.io" },
    "created_at": { "S": "2025-10-19T09:00:01Z" },
    "ttl_epoch": { "N": "1760000000" }
  }
}


(When coding with AWS SDK DocumentClient this maps to plain JS object ‚Äî the SDK handles types for you.)

5 ‚Äî Useful extras & best practices

TTL (Time To Live): if you only need X days of weather history, enable TTL on ttl_epoch so DynamoDB auto-expunges old rows.

GSI (optional): if you need to query by weather_code or source often, create a Global Secondary Index. Example: GSI on weather_code + timestamp.

Batch writes: when storing multiple forecast horizons (0..24) for a location, do BatchWriteItem to insert multiple items fast.

Storage model: store one item per (location, timestamp, forecast_horizon). If you want a single document with multiple horizons, you can store a forecasts map ‚Äî but that makes range queries by time harder.

Partition key design: use consistent location IDs (avoid long free-text). site-<id> or lat_lon rounded to a resolution (e.g., 4 decimals) work well.

6 ‚Äî IoT integration notes (how data flows)

Option A ‚Äî Backend pulls from Tomorrow.io and writes to DynamoDB

Your Node.js backend fetches forecast for a location, then writes one or more items into weather_data.

PLCnext receives commands via MQTT that are computed using those stored forecasts and telemetry.

Option B ‚Äî AWS IoT Rule writes directly to DynamoDB

If you want to save IoT Core messages directly to DynamoDB, you can configure an IoT Rule to insert into weather_data (but you‚Äôll still typically fetch weather from backend).

For security and enrichment (e.g., resolve lat/lon to location ID), doing the write in your backend is better.

7 ‚Äî Example minimal IAM policy (for backend role)

Ensure the role your backend uses (EC2/Beanstalk/ECS task role / Lambda role) has at least this permission:

{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Effect": "Allow",
      "Action": [
        "dynamodb:PutItem",
        "dynamodb:BatchWriteItem",
        "dynamodb:GetItem",
        "dynamodb:Query",
        "dynamodb:Scan"
      ],
      "Resource": "arn:aws:dynamodb:eu-north-1:514190630121:table/weather_data"
    }
  ]
}


Adjust the account ID and region to yours.

8 ‚Äî Quick example: what to store per PLC publish event

When PLC publishes telemetry and you enrich it with weather before saving, store weather in weather_data and telemetry in telemetry_data (separate table). Keep them linked via location + timestamp keys. This keeps responsibilities separate and queries simple.

If you want I can:

Generate the exact AWS CLI create-table command with PAY_PER_REQUEST and a TTL attribute, ready to paste;

Produce a DocumentClient example (Node.js) to put one item into weather_data;

Provide the IoT Rule JSON to forward an MQTT topic to DynamoDB (if you want direct IoT ‚Üí DynamoDB writes).

Which of those would you like next?

You said:
lets now create backend code for node.js
ChatGPT said:

Perfect üëç ‚Äî now that your goal is to collect weather data (from Tomorrow.io) and store it in DynamoDB, we‚Äôll build a simple Node.js backend that:

Fetches weather data from Tomorrow.io API using your API key.

Saves it into your DynamoDB table (weather_data).

Exposes REST endpoints for your frontend (Next.js) to access data.

Let‚Äôs walk step-by-step.

üß© 1. Folder setup

In your terminal:

mkdir backend-weather
cd backend-weather
npm init -y
npm install express aws-sdk axios dotenv


This installs:

express ‚Üí for your API routes

aws-sdk ‚Üí to connect to DynamoDB

axios ‚Üí to call Tomorrow.io API

dotenv ‚Üí to load API keys from .env

‚öôÔ∏è 2. Create .env

Create a file named .env in the project root:

PORT=8080
AWS_REGION=eu-north-1
TOMORROW_API_KEY=KrkAgr7zHhH6Ee*****QnBgpPgaXtq
DYNAMO_TABLE=weather_data


(Use your real API key.)

üß† 3. Backend structure
backend-weather/
‚îÇ
‚îú‚îÄ‚îÄ index.js
‚îú‚îÄ‚îÄ .env
‚îî‚îÄ‚îÄ package.json

üöÄ 4. Code ‚Äî index.js
import express from 'express';
import axios from 'axios';
import AWS from 'aws-sdk';
import dotenv from 'dotenv';

dotenv.config();
const app = express();
app.use(express.json());

// Environment variables
const { PORT, AWS_REGION, TOMORROW_API_KEY, DYNAMO_TABLE } = process.env;

// AWS SDK setup
AWS.config.update({ region: AWS_REGION });
const dynamoDB = new AWS.DynamoDB.DocumentClient();

// Tomorrow.io API endpoint
const BASE_URL = 'https://api.tomorrow.io/v4/weather/realtime';

// üõ∞Ô∏è Route 1: Fetch weather and store to DynamoDB
app.get('/weather/update', async (req, res) => {
  try {
    // Replace with your PLC site coordinates
    const lat = -25.746;  // Example: Pretoria
    const lon = 28.188;

    // Call Tomorrow.io API
    const response = await axios.get(`${BASE_URL}`, {
      params: {
        location: `${lat},${lon}`,
        apikey: TOMORROW_API_KEY
      }
    });

    const data = response.data.data.values;
    const timestamp = new Date().toISOString();

    const weatherItem = {
      location: `${lat},${lon}`,
      timestamp,
      temperature_c: data.temperature,
      irradiance_w_m2: data.solarGHI,
      cloud_cover_pct: data.cloudCover,
      wind_speed_m_s: data.windSpeed,
      humidity_pct: data.humidity,
      precipitation_mm: data.precipitationIntensity,
      source: 'tomorrow.io',
      created_at: timestamp
    };

    // Store to DynamoDB
    await dynamoDB.put({
      TableName: DYNAMO_TABLE,
      Item: weatherItem
    }).promise();

    res.json({
      message: 'Weather data updated successfully',
      weatherItem
    });
  } catch (err) {
    console.error('Error fetching weather:', err.message);
    res.status(500).json({ error: err.message });
  }
});

// üìä Route 2: Get recent weather data
app.get('/weather/latest', async (req, res) => {
  try {
    const location = req.query.location || '-25.746,28.188';
    const params = {
      TableName: DYNAMO_TABLE,
      KeyConditionExpression: '#loc = :loc',
      ExpressionAttributeNames: { '#loc': 'location' },
      ExpressionAttributeValues: { ':loc': location },
      Limit: 10,
      ScanIndexForward: false // newest first
    };

    const result = await dynamoDB.query(params).promise();
    res.json(result.Items);
  } catch (err) {
    console.error('Error fetching latest data:', err.message);
    res.status(500).json({ error: err.message });
  }
});

// ‚úÖ Health check
app.get('/', (req, res) => {
  res.json({
    message: 'Weather backend running',
    endpoints: ['/weather/update', '/weather/latest']
  });
});

// Run server
app.listen(PORT, () => console.log(`üöÄ Server running on port ${PORT}`));

üîê 5. Run locally
node index.js


Then visit:

http://localhost:8080/weather/update


‚û° It will call Tomorrow.io ‚Üí fetch data ‚Üí save to DynamoDB.
To see data:

http://localhost:8080/weather/latest

üå©Ô∏è 6. Deploy to AWS Elastic Beanstalk

In your project directory:

eb init
eb deploy


Your deployed backend will then have the routes:

https://your-env.elasticbeanstalk.com/weather/update
https://your-env.elasticbeanstalk.com/weather/latest

‚ö° 7. Connect to React / Next.js frontend

Your frontend will:

Call GET /weather/latest to display live or historical weather data

Call GET /weather/update (admin-only) to trigger refresh or store new forecast

Combine this with IoT telemetry for solar prediction or efficiency calculation

Would you like me to help you add a cron job (automatic scheduler) so your backend fetches and saves new weather data every hour automatically ‚Äî without you calling /weather/update manually?

You said:

Would you like me to help you add a cron job (automatic scheduler

Yea let‚Äôs add a cron job for 30 minutes , 1 hour, 4 hours and 1 day
ChatGPT said:

Excellent ‚úÖ ‚Äî here‚Äôs how you can add automatic weather updates every 30 minutes, 1 hour, 4 hours, and 1 day right inside your Node.js backend.

We‚Äôll use the node-cron package to schedule periodic fetches from Tomorrow.io and insert them into DynamoDB ‚Äî no manual /weather/update needed.

üß© Step 1: Install node-cron

In your backend folder:

npm install node-cron

‚öôÔ∏è Step 2: Import and schedule inside index.js

At the top of your backend file:

import cron from 'node-cron';


Then after your routes (but before app.listen(...)), add:

// üïí CRON SCHEDULERS FOR WEATHER UPDATES

// Every 30 minutes
cron.schedule('*/30 * * * *', () => {
  console.log('‚è±Ô∏è Running 30-min weather update...');
  fetchAndStoreWeather();
});

// Every 1 hour
cron.schedule('0 * * * *', () => {
  console.log('‚è±Ô∏è Running 1-hour weather update...');
  fetchAndStoreWeather();
});

// Every 4 hours
cron.schedule('0 */4 * * *', () => {
  console.log('‚è±Ô∏è Running 4-hour weather update...');
  fetchAndStoreWeather();
});

// Every 1 day
cron.schedule('0 0 * * *', () => {
  console.log('‚è±Ô∏è Running daily weather update...');
  fetchAndStoreWeather();
});

‚ö° Step 3: Move your API logic into a reusable function

Above the cron section, extract your weather fetching logic like this:

async function fetchAndStoreWeather() {
  try {
    const lat = -25.746;  
    const lon = 28.188;

    const response = await axios.get(BASE_URL, {
      params: { location: `${lat},${lon}`, apikey: TOMORROW_API_KEY }
    });

    const data = response.data.data.values;
    const timestamp = new Date().toISOString();

    const weatherItem = {
      location: `${lat},${lon}`,
      timestamp,
      temperature_c: data.temperature,
      irradiance_w_m2: data.solarGHI,
      cloud_cover_pct: data.cloudCover,
      wind_speed_m_s: data.windSpeed,
      humidity_pct: data.humidity,
      precipitation_mm: data.precipitationIntensity,
      source: 'tomorrow.io',
      created_at: timestamp
    };

    await dynamoDB.put({ TableName: DYNAMO_TABLE, Item: weatherItem }).promise();
    console.log(`‚úÖ Weather data saved at ${timestamp}`);
  } catch (err) {
    console.error('‚ùå Cron job error:', err.message);
  }
}

üß† Step 4: That‚Äôs it!

Now your backend:

Automatically fetches and stores weather data every 30 min, 1h, 4h, and 24h.

Continues to work manually via /weather/update endpoint.

Keeps DynamoDB always up-to-date for your React/Next.js dashboard.

Would you like me to show you how to see the cron job logs in AWS Elastic Beanstalk (via CloudWatch) so you can confirm it‚Äôs running successfully after deployment?

You said:
Yes 
ChatGPT said:

Perfect üëå ‚Äî here‚Äôs how to view your Node.js cron job logs in AWS Elastic Beanstalk using CloudWatch, so you can confirm that your scheduled weather updates (every 30 min, 1 h, 4 h, and 1 day) are actually running after deployment.

ü™∂ Step 1: Enable CloudWatch Logs for your EB environment

Go to your AWS Console ‚Üí Elastic Beanstalk

Open your environment (e.g. backend-solar-env)

In the left menu ‚Üí click Configuration

Under Monitoring, click Edit

Enable ‚úÖ Log streaming to CloudWatch Logs

Scroll down ‚Üí click Apply

üìç This tells AWS to automatically forward your Node.js console.log() output to CloudWatch.

üßæ Step 2: Verify that logging is active

In the same Configuration page, click Logs

Choose Request logs ‚Üí Last 100 lines

You‚Äôll get a ZIP file with logs

Open web.stdout.log ‚Äî you should see your cron prints like:

‚è±Ô∏è Running 30-min weather update...
‚úÖ Weather data saved at 2025-10-20T09:30:00Z

‚òÅÔ∏è Step 3: Open CloudWatch

In the AWS Console, search CloudWatch

Go to Logs ‚Üí Log groups

Find your Beanstalk log group ‚Äî it looks like:

/aws/elasticbeanstalk/backend-solar-env/var/log/web.stdout.log


Click it ‚Üí click the latest log stream

Here you‚Äôll see real-time console output from your Node.js app

Every cron run will appear automatically üéØ

üõ†Ô∏è Step 4: Optional ‚Äî add a custom tag for logs

If you want logs to be easier to filter:

console.log('[CRON] 30min weather update started');


Then in CloudWatch Logs Insights, you can query:

fields @timestamp, @message
| filter @message like /CRON/
| sort @timestamp desc

üí° Step 5: (Optional) Send alerts if cron fails

You can later set a CloudWatch Alarm:

Metric: ErrorCount

Condition: if >= 1 in 1 hour

Action: send SNS or email notification

‚úÖ Summary
Once enabled:

Every console log from fetchAndStoreWeather() (like ‚úÖ Weather data saved) appears in CloudWatch automatically.

You can track all cron activity, troubleshoot errors, and confirm timestamps of runs.

Would you like me to show you how to trigger the cron job manually on Elastic Beanstalk (for testing before the 30 min job runs)?

You said:
Then on the frontend we will have to select and change the location I want to search for location then we will use use our weather tommorw to predict weather for that area and send it to our db
ChatGPT said:

Perfect ‚úÖ ‚Äî that‚Äôs a great next step and exactly how a real-world IoT + weather intelligence system should behave.

Here‚Äôs how we‚Äôll structure this new frontend + backend workflow so that users can select any location, get its forecast from Tomorrow.io, and save it into your DynamoDB weather table automatically.

üåç High-Level Flow

Frontend (Next.js)

User selects or searches a location (city or coordinates).

The frontend sends a request to your backend, e.g.:

POST /api/weather
{
  "location": "Cape Town"
}


Backend (Node.js + Tomorrow.io API)

Receives the location name.

Uses Tomorrow.io API to fetch weather forecast for that location.

Processes the response (temperature, humidity, irradiance, wind, etc.).

Saves the result to your DynamoDB weather table.

Returns the data to the frontend for live visualization.

Frontend (Next.js)

Displays the weather prediction graph or metrics (temperature, irradiance, etc.).

Optionally lets users ‚Äúsend to PLC‚Äù (publishing to AWS IoT).

üß± Proposed DynamoDB Weather Table (Simplified)
Attribute Name	Type	Description
id	String (UUID)	Unique entry ID
location	String	City or coordinates
temperature	Number	¬∞C
irradiance	Number	Solar irradiance (W/m¬≤)
humidity	Number	%
wind_speed	Number	m/s
forecast_time	String	ISO timestamp
created_at	String	When data was fetched
üß† Frontend Functionality Plan (Next.js)

Page: /weather

Input field or map search for ‚ÄúLocation‚Äù.

‚ÄúGet Forecast‚Äù button ‚Üí triggers API call to backend.

Backend returns weather data ‚Üí display chart and values.

‚ÄúSave to Database‚Äù (optional toggle ‚Äî or automatic).

‚ÄúPublish to PLC‚Äù (optional for AWS IoT message).

We can use:

React Query or Axios to fetch weather data.

Chart.js or Recharts to visualize forecasts (irradiance, temp, etc.).

üîó Example Backend Endpoint

POST /api/weather

{
  "location": "Cape Town"
}


Response:

{
  "location": "Cape Town",
  "temperature": 26.4,
  "irradiance": 830,
  "humidity": 48,
  "wind_speed": 5.1,
  "forecast_time": "2025-10-20T12:00:00Z"
}

‚öôÔ∏è Next Step Options

We can now proceed in one of two ways:

Option A (Backend first) ‚Üí I show you how to update your Node.js backend to:

Accept a /api/weather request with a location

Call Tomorrow.io API

Save the forecast to DynamoDB

Return it to frontend

Option B (Frontend first) ‚Üí I show you how to create the Next.js page for searching and visualizing the forecast.

üëâ Which one do you want to start with ‚Äî Backend first or Frontend first?

You said:
I created my table like this. {
  "TableName": "weather_data",
  "Item": {
    "location": { "S": "-25.746,28.188" },
    "timestamp": { "S": "2025-10-19T09:00:00Z" },
    "forecast_horizon": { "N": "0" },
    "temperature_c": { "N": "23.4" },
    "irradiance_w_m2": { "N": "820" },
    "cloud_cover_pct": { "N": "12" },
    "weather_code": { "S": "clear" },
    "wind_speed_m_s": { "N": "4.3" },
    "humidity_pct": { "N": "60" },
    "precipitation_mm": { "N": "0.0" },
    "source": { "S": "tomorrow.io" },
    "created_at": { "S": "2025-10-19T09:00:01Z" },
    "ttl_epoch": { "N": "1760000000" }
  }
} must update it show me frontend first and which packages must I use to allow users to search for their locations . Let‚Äôs allow users to search for their location and save their location for future use
ChatGPT said:

Perfect üëå you‚Äôre already structuring your weather_data table very well ‚Äî it‚Äôs clean, scalable, and ready for real-time forecasting integration.

Now, since you want to start with the frontend (Next.js) part, let‚Äôs build this step-by-step so users can:
‚úÖ Search for their location
‚úÖ Save that location for later use
‚úÖ Trigger fetching + storing weather data for that location

üåç Goal of the Frontend Module

We‚Äôll create a page where the user can:

Search for a location (autocomplete or manual input)

Select one

Save it to their account (localStorage or backend DB)

Trigger backend call to fetch Tomorrow.io weather for that location

üß∞ Recommended Packages for Next.js Frontend
Purpose	Package	Description
Location search	react-places-autocomplete or @react-google-maps/api	Google Maps location search and coordinates
API requests	axios	Easy HTTP requests to your Node.js backend
State management	react-query or zustand (optional)	Caching and refreshing weather data
Charts	react-chartjs-2	For displaying weather/irradiance graphs
Persistent storage	built-in localStorage	Save previously selected locations locally
üß≠ Step-by-Step Setup Guide
üß© Step 1: Create a Next.js page

In your project:

npx create-next-app@latest weather-dashboard
cd weather-dashboard
npm install axios react-places-autocomplete


You‚Äôll now have a folder structure like:

/pages
  ‚îú‚îÄ‚îÄ index.js
  ‚îú‚îÄ‚îÄ weather.js   ‚Üê main page for searching & viewing

üó∫Ô∏è Step 2: Enable location search (React Places Autocomplete)

To use Google Maps Places API, go to
üëâ https://console.cloud.google.com

Enable Places API and Maps JavaScript API, then get your Google Maps API key.

Add it to your .env.local:

NEXT_PUBLIC_GOOGLE_MAPS_API_KEY=YOUR_KEY_HERE

üß± Step 3: Create weather.js page

Example structure (no backend code yet):

"use client";
import React, { useState } from "react";
import PlacesAutocomplete, {
  geocodeByAddress,
  getLatLng
} from "react-places-autocomplete";
import axios from "axios";

export default function WeatherSearch() {
  const [address, setAddress] = useState("");
  const [coordinates, setCoordinates] = useState({ lat: null, lng: null });
  const [savedLocations, setSavedLocations] = useState(
    JSON.parse(localStorage.getItem("locations") || "[]")
  );

  const handleSelect = async (value) => {
    const results = await geocodeByAddress(value);
    const latLng = await getLatLng(results[0]);
    setAddress(value);
    setCoordinates(latLng);
  };

  const saveLocation = () => {
    const newLocation = { address, ...coordinates };
    const updated = [...savedLocations, newLocation];
    setSavedLocations(updated);
    localStorage.setItem("locations", JSON.stringify(updated));
  };

  const fetchWeather = async () => {
    const res = await axios.post("/api/weather", {
      location: `${coordinates.lat},${coordinates.lng}`
    });
    console.log(res.data); // You‚Äôll connect this to your charts later
  };

  return (
    <div style={{ padding: "2rem" }}>
      <h1>üå§Ô∏è Weather Forecast Search</h1>
      <PlacesAutocomplete
        value={address}
        onChange={setAddress}
        onSelect={handleSelect}
      >
        {({ getInputProps, suggestions, getSuggestionItemProps, loading }) => (
          <div>
            <input {...getInputProps({ placeholder: "Search location..." })} />
            <div>
              {loading && <div>Loading...</div>}
              {suggestions.map((s) => (
                <div key={s.placeId} {...getSuggestionItemProps(s)}>
                  {s.description}
                </div>
              ))}
            </div>
          </div>
        )}
      </PlacesAutocomplete>

      <button onClick={saveLocation} disabled={!address}>Save Location</button>
      <button onClick={fetchWeather} disabled={!coordinates.lat}>Get Weather</button>

      <h2>Saved Locations</h2>
      <ul>
        {savedLocations.map((loc, i) => (
          <li key={i}>{loc.address}</li>
        ))}
      </ul>
    </div>
  );
}

üß† Step 4: Local caching of user locations

Locations are saved in localStorage, so they persist even after reload.

Later, you can link this to user accounts (if you add authentication).

üß© Step 5: Integrate with backend /api/weather

When users click ‚ÄúGet Weather‚Äù, it will:

Send { lat, lng } to your backend.

Backend calls Tomorrow.io API.

Save weather data to DynamoDB.

Return it back for display.

You already have the table ready (weather_data), so next we‚Äôll wire this backend endpoint.

Would you like me to show you the backend code for that /api/weather endpoint next (with Tomorrow.io + DynamoDB integration + cron jobs)?

ChatGPT can make mistakes. Check important info. See Cookie Preferences.